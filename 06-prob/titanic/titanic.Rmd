---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.14.5
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

<!-- #region slideshow={"slide_type": "slide"} -->
# Titanic dataset
<!-- #endregion -->

This assigment consists of the introductory problem [Titanic: Machine Learning from Disaster](https://www.kaggle.com/c/titanic). The goal is to train a classifier to predict persons that have survived the disaster. 


We will start by reading in the, by now standard, Titanic dataset. It contains information about passengers of the Titanic. The information includes i.a. sex, age, name  and passenger class as well as information if the passenger survived or died in the disaster. You can find more details about this data set [here](http://campus.lakeforest.edu/frank/FILES/MLFfiles/Bio150/Titanic/TitanicMETA.pdf). 


The data  is in "coma separated values" (csv) format and to read it we will use the [pandas](https://pandas.pydata.org) library. Pandas  provides tools for manipulating  data frames and series and is wildly used in data science projects. 

Please note that this is NOT a pandas manual. For detailed explanation of the concepts and functions used here you should consult the [documentation](https://pandas.pydata.org/pandas-docs/stable/getting_started/index.html). 

```{python}
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams['figure.figsize'] = (8.0, 6.0)
import pandas as pd
```

```{python}
data_all = pd.read_csv("titanic3.csv")
```

`data_all` is a pandas  [_DataFrame_](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html) object. 

```{python}
type(data_all)
```

We can check what attributes are stored in the DataFrame by listing the column names:

```{python}
data_all.columns
```

or get a quick preview using ```head``` function: 

```{python}
data_all.head(2)
```

For the description of those features please see the before mentioned [link](http://campus.lakeforest.edu/frank/FILES/MLFfiles/Bio150/Titanic/TitanicMETA.pdf). 


Another usefull function is ```info```:

```{python}
data_all.info()
```

As we can see not all attributes are known (non-null) for every passanger. This is a frequent situation in real datasets. 

```{python}
data_all.survived.value_counts()/len(data_all)
```

### Train/test split


As in every machine learning problem we should split our data into training and testing sets.

```{python}
from sklearn.model_selection import train_test_split
```

```{python}
seed = 5657
train_data, test_data = train_test_split(data_all, train_size=0.8, stratify=data_all.survived, random_state=seed)
```

```{python}
train_data.info()
```

```{python}
test_data.info()
```

```{python}
train_data.survived.value_counts()/len(train_data)
```

```{python}
test_data.survived.value_counts()/len(test_data)
```

## Problem 1


__a__) Implement a Bayes classifier for predicting passenger survival  using sex and pclass  features.


Actually this problem will be partially solved for you below to serve as an tutorial on pandas :) 


#### Preliminaries


We will start by extracting from the frame  only the information we need:

```{python}
train_data = train_data[['pclass', 'sex', 'survived']]
test_data = test_data[['pclass', 'sex', 'survived']]
```

```{python}
train_n_samples = len(train_data)
test_n_samples = len(test_data)
```

```{python}
train_data.head(5)
```

First we need to group passengers according to sex, class and survival status. This can be achieved using  the [`groupby`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html) function:

```{python}
train_grouped = train_data.groupby(['survived','sex','pclass'])
```

We can count the number of passegers in each group using function ```size```:

```{python}
train_counts = train_grouped.size()
```

Object ```train_counts``` contains all the information that we need to construct the classifier:

```{python}
train_counts
```

`train_counts` is a pandas [_Series_](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html) object indexed by a [_MultiIndex_](https://pandas.pydata.org/pandas-docs/stable/user_guide/advanced.html#advanced-hierarchical).

```{python}
train_counts.index
```

We can treat a multi-indexed series as an multi-dimensional table with each level of the index corresponding to one dimension. You can index `counts` to obtain information on specified entry: 

```{python}
train_counts[1,'female',2]
```

The index is hierarchical, if we do not provide all indices, a subset of elements will be returned e.g. 

```{python}
train_counts[1,'female']
```

list the number of male surviving women  in each class. Similarly 

```{python}
train_counts[1]
```

lists the number of survivors for each sex and class.


It is however better to use the `loc` function. With this function we can also use the _slicing_ notation. For example 

```{python}
train_counts.loc[0, :,3]
```

list non-survivors in third class grouped according to sex. 


Both `[]` and `loc[]` can  also take a _tuple_ as an argument: 

```{python}
train_counts.loc[(0, 'female',3)]
```

but the use of slice notation in tuple is not permitted. You can use it by providing an explicit _slice_ object 

```{python}
train_counts.loc[(0, slice(None),3)]
```

Function `sum`  as expected returns the sum of all the entries of the series e.g. 

```{python}
train_n_survivors = train_counts[1].sum()
train_n_dead = train_counts[0].sum()
```

### Classifier


To implement classifier we need to calculate the conditional probability of survival given sex and class:


$$P(survived|sex, pclass)$$


$survived$ here is the label that can take two values 0 for dead and 1 for survivors, but we can  calculate only the survival probability because of the relation


$$P(survived=1|sex, pclass)+P(survived=0|sex, pclass)=1$$


We can use the Bayes theorem but it will be actually quicker to calculate it directly from the definition:


$$P(survived|sex, pclass)=\frac{P(survived,sex, pclass)}{P(sex, pclass)}
\approx \frac{\#(survived,sex, pclass)}{\#(sex,pclass)}$$


where by $\#$ I have denoted the number of passengers with given attributes. For example the probability of survival for a women traveling in second class is: 


$$\frac{\text{number of women in second class that survived}}{\text{number of women in second class}}$$


which we can calculate as

```{python}
train_counts[(1,'female',2)]/(train_counts[(1,'female',2)]+train_counts[(0,'female',2)])
```

This operation has to be repeated for every sex and class combination. We do not have to do it index by index. Pandas have overloaded arithmetic operations that work  on all indices at once e.g. 

```{python}
by_sex_pclass = train_counts.loc[0]+train_counts.loc[1]
```

creates a series with number of passengers of each gender and class

```{python}
by_sex_pclass
```

Same effect can be achieved by passing `level` argument to the series `sum` function. The level argument lists the levels which are __not__ summed over. In other words those are the levels left after summation. To sum over the `survived` level we use

```{python}
by_sex_class = train_counts.groupby(level=['sex','pclass']).sum()
```

Using `train_counts` and `by_sex_class` you can calculate required conditional propabilities. 

```{python}
p_surv_cond_sex_pclass = (train_counts/by_sex_pclass)
p_surv_cond_sex_pclass = p_surv_cond_sex_pclass.reorder_levels(['survived','sex','pclass']).sort_index()
```

```{python}
p_surv_cond_sex_pclass
```

In the above expression we have used a very useful feature of pandas series. When performing an arithmetic operation  the elements of the series are _joined_ based on the common index levels.  


`train_counts` have three levels of index

```{python}
train_counts.index.names
```

and `by_sex_class` has two

```{python}
by_sex_class.index.names
```

Levels 'sex' and 'pclass' are common to both indexes so the expression


```p_surv_cond_sex_pclass = (counts/by_sex_class)```


will have a three level index with  levels 'survived', 'sex' and 'pclass'  and is equivalent to:

```{python}
p_surv_cond_sex_pclass = pd.Series(0,index=train_counts.index)
for survived, sex, pclass in train_counts.index: 
    p = train_counts.loc[survived, sex, pclass]/by_sex_class.loc[sex, pclass]
    p_surv_cond_sex_pclass.loc[(survived, sex, pclass)] = p
```

Unfortunatelly the automatic join operation also reorders the levels of the multi index so we have to order them back using `reorder_levels` and `sort_index` function.


```p_surv_cond_sex_pclass = (counts/by_sex_class).reorder_levels(['survived','sex','pclass']).sort_index()```


We can check that we indeed get the identical values

```{python tags=c("answer")}
p_surv_cond_sex_pclass
```

```{python}
p_surv_cond_sex_pclass.groupby(level=['sex', 'pclass']).sum()
```

#### b) Calculate TPR and FPR on the train and test set. Draw the ROC curve and calculate AUC score for both sets.


The TPR is the fraction of survivors that were classified as survivors. And FPR is the fraction of dead persons that were classified as survivors. We classify a person as survivor when the probability of survival is  greater or equal to one half. 


For ROC and AUC use the functions from scikit-learn library.


#### c) Are those features conditionally independent? 


To answer this question we need to compare conditional probability distribution


$$P(sex,pclass|survived)$$


with


$$P(sex|survived)\times P(pclass|survived)$$ 


Please note that $survived$ is actually a label for the survival status: 1 for survived and 0 for dead. 


By definition


$$P(sex,pclass|survived)= \frac{P(sex,pclass,survived)}{P(survived)}$$


which can be calculated based on the `train_counts` object. 


#### d) Implement a Naive bayes classifier using same features and compare it with a)


Please calculate the FPR and TPR as well as AUC and draw the ROC curve for train and test datasets. 


We  have already calculated the probability 


$$P_{NB}(sex,pclass|survived) = P(sex|survived)\times P(pclass|survived)$$


From which we can calculate 


$$P_{NB}(survived|sex,pclass)= \frac{P_{NB}(sex,pclass|survived)P(survived)}{P_{NB}(sex,pclass)}$$


where the denominator is also calculated from the factorised probabilities


$$P_{NB}(sex,pclass)= P_{NB}(sex,pclass|survived=1)P(survived=1)+P_{NB}(sex,pclass|survived=0)P(survived=0)$$


That is very important because the result must be a probability and add up to one


$$P_{NB}(survived=1|sex,pclass)+P_{NB}(survived=0|sex,pclass)=1$$


for each sex and passenger class. 
